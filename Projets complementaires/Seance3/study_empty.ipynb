{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contexte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce projet rentre dans la formation \"Artificial Intelligence for robotics with Python\" proposée par Micro Club. A travers ce court projet vous aurez à revoir les principes de classification utilisant des méthodes de Machine Learning classique comme vus durant la séance 3. \n",
    "\n",
    "Ce projet se base sur ce [dataset](https://www.kaggle.com/datasets/andrewmvd/fetal-health-classification) donnant les données CTG (cardiotocogramme) pour définir les taux de risques de maladie de foetus, donc l'objectif est de classer les différents cas en trois catégories : \n",
    "- Normal : 1\n",
    "- Suspect : 2\n",
    "- Malade : 3\n",
    "\n",
    "Ainsi ce genre de projet vous permettra de vous entraîner sur de vrais problématiques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "# Pré-traitement des données\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Pour tester les performances des modèles utilisés\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des modèles de Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importez les modèles que vous voulez évaluer sur cette problématique à partir de la librairie scikit-learn. Voici la documentation officielle : [Documentation](https://scikit-learn.org/stable/supervised_learning.html)\n",
    "\n",
    "Choisissez 4 modèles à évaluer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importer le fichier \"fetal_health.csv\" proposé avec ce challenge en utilisant Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisant Pandas veuillez faire une analyse rapide des données : \n",
    "- Faire une description globale des données (describe)\n",
    "- Expliquez si on a besoin ou pas d'une normalisation des données\n",
    "- Indiquer si on a des valeurs manquante ou pas\n",
    "- Indiquer la distribution (ou le nombre d'échantillon par classe) des différentes classes qu'on a (colonne : fetal_health)\n",
    "- Voyez la corrélation entre les différentes features qu'on a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisant matplotlib et Seaborn : \n",
    "- Faites une visualisation de la matrice de corrélation précédemment réalisée et commentez la\n",
    "- Faites une visualisation des différentes distributions et relations entre les variables utilisant seaborn (pairplot) par rapport à chaque classe\n",
    "- Faites un ensemble de visualisations sur les données (faites celles que vous jugez pertinentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisant les différentes fonctions de scikit-learn : \n",
    "- D'après votre analyse et visualisation des données, supprimez s'il le faut les features que vous jugez en trop\n",
    "- Subdivisez les données en un ensemble d'entrainement et de test, prenez 30% du jeux de données pour le test, le reste sera pris pour l'entrainement.\n",
    "- Appliquez une normalisation (s'il le faut) aux données d'entrainement ainsi qu'aux données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application des modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisant scikit-learn :\n",
    "- Appliquez les modèles que vous avez sélectionné pour la classification de ces données\n",
    "- Evaluez les performances des modèles utilisant : l'accuracy, f1-score\n",
    "- Utilisez GridSearchCV pour sélectionner les meilleurs paramètres pour vos différents modèles\n",
    "- Indiquez pour chaque modèle sélectionné quelle est la meilleure combinaison de paramètres\n",
    "- Indiquez pour chaque modèle sélectionné les performances (en terme de métrique) maximales atteintes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour aller plus loin : \n",
    "- Features engineering\n",
    "    - Etudiez les techniques de sélection de caractéristiques (features selection) : [Source intéressante](https://machinelearningmastery.com/calculate-feature-importance-with-python/)\n",
    "    - Garder les features les plus importantes utilisant les techniques précédemment présentées (choisissez le nombre de caractéristiques sélectionnées que vous voulez)\n",
    "    - Evaluez le modèle avec ce nombre de features et analysez s'il gagne ou perd en performances\n",
    "- Dimensionality reduction\n",
    "    - Etudiez l'analyse en composantes principales (PCA) : [Source](https://builtin.com/data-science/step-step-explanation-principal-component-analysis)\n",
    "    - Appliquez la PCA utilisant scikit-learn\n",
    "    - Appliquez la PCA pour garder les 2 composantes principales et faites une visualisation (scatter plot) de vos données en mettant une couleur par classes et analysez la facilité (ou difficulté) de classification\n",
    "    - Sélectionner un nombre de composantes principales permettant d'avoir au moins 90% de la variance globale du jeux de données initial\n",
    "    - Appliquez à nouveau les modèles que vous avez sélectionnés et analysez les performances atteintes via cette technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
